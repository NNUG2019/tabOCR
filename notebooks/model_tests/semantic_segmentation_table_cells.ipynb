{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "semantic_segmentation_dominik_cell.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZkJRPXWCbhQ",
        "colab_type": "code",
        "outputId": "1902a76e-9939-45c6-896e-624214744e73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        }
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "from keras.layers import Conv2D, MaxPooling2D, Dropout, Input, concatenate, UpSampling2D, Activation, Reshape, Conv2DTranspose\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.utils import Sequence\n",
        "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
        "from google.colab import files, drive\n",
        "from skimage.io import imread, imsave\n",
        "from skimage.transform import resize\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import io\n",
        "import zipfile\n",
        "import cv2\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cQ05e8fYiGp",
        "colab_type": "code",
        "outputId": "5a28433f-5e11-4ddb-ef15-2abc0eae1f56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "drive.mount('/content/gdrive', force_remount=True)\n",
        "root_path = 'gdrive/My Drive/tabOCR/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_1SZNgR9xUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#uploaded = files.upload()\n",
        "#data = zipfile.ZipFile(io.BytesIO(uploaded['dataset_ann2.zip']), 'r')\n",
        "#data.extractall()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHYlttwbCS0L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_height = 1024\n",
        "input_width = 1024\n",
        "n_classes = 51\n",
        "batch_size = 2\n",
        "loss = 'categorical_crossentropy'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0ZhpW3Y2tyU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXr4CM_nWrHV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class image_generator(Sequence):\n",
        "\n",
        "    def __init__(self, image_filenames, mask_filenames, batch_size, img_size, n_calsses, loss='categorical_crossentropy', no_reshape=False):\n",
        "        self.image_filenames, self.mask_filenames = image_filenames, mask_filenames\n",
        "        self.batch_size = batch_size\n",
        "        self.height = img_size[0]\n",
        "        self.width = img_size[1]\n",
        "        self.n_calsses = n_calsses\n",
        "        self.no_reshape = no_reshape\n",
        "        self.loss = loss\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
        "\n",
        "    def get_img_array(self, file_name):\n",
        "      img = cv2.imread(file_name, 3)\n",
        "      return cv2.resize(img, (self.height, self.width)).astype('float32')\n",
        "\n",
        "    def get_segmentation_mask(self, file_name):\n",
        "        img = cv2.imread(file_name, 1)\n",
        "        img = cv2.resize(img, (self.height, self.width), interpolation=cv2.INTER_NEAREST)\n",
        "        img = img[:, :, 0]\n",
        "        seg_labels = np.zeros((self.width, self.height, self.n_calsses))\n",
        "        for c in range(self.n_calsses):\n",
        "          seg_labels[:, :, c] = (img == c).astype(int)\n",
        "        if not self.no_reshape:\n",
        "          seg_labels = np.reshape(seg_labels, (self.height*self.width, self.n_calsses))\n",
        "        return seg_labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_y = self.mask_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        if self.loss == 'categorical_crossentropy':\n",
        "           return (np.array([self.get_img_array(file_name) for file_name in batch_x]),\n",
        "                   np.array([self.get_segmentation_mask(file_name) for file_name in batch_y]))\n",
        "        else:\n",
        "          return (np.array([self.get_img_array(file_name)for file_name in batch_x]),\n",
        "                  np.array([self.get_segmentation_mask(file_name) for file_name in batch_y]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mMignxGLPhNZ",
        "colab_type": "code",
        "outputId": "6baaab84-5dbb-4976-8f11-90bb0136144a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# from drive\n",
        "'''\n",
        "image_filenames = []\n",
        "mask_filenames = []\n",
        "for path, _, files in os.walk(root_path + \"table_imgs_train\"):\n",
        "    for f in files:\n",
        "        imgs.append(os.path.join(path, f))\n",
        "for path, _, files in os.walk(root_path + \"table_mask_cell_train\"):\n",
        "    for f in files:\n",
        "        masks.append(os.path.join(path, f))\n",
        "train_generator = generator_disk(image_filenames, mask_filenames, batch_size=4, img_size=(input_height, input_width), n_calsses=n_classes, loss=loss)\n",
        "'''\n",
        "\n",
        "# from uploaded\n",
        "image_filenames = list(map(lambda s: \"img_table/\" + s, sorted(os.listdir('img_table'))))\n",
        "mask_filenames = list(map(lambda s: \"img_mask_cell/\" + s, sorted(os.listdir('img_mask_cell'))))\n",
        "image_filenames_val = list(map(lambda s: \"img_table_val/\" + s, sorted(os.listdir('img_table_val'))))\n",
        "mask_filenames_val = list(map(lambda s: \"img_mask_cell_val/\" + s, sorted(os.listdir('img_mask_cell_val'))))\n",
        "train_generator = image_generator(image_filenames, mask_filenames, batch_size=batch_size, img_size=(input_height, input_width), n_calsses=n_classes, loss=loss)\n",
        "val_generator = image_generator(image_filenames_val, mask_filenames_val, batch_size=batch_size, img_size=(input_height, input_width), n_calsses=n_classes, loss=loss)\n",
        "\n",
        "t = train_generator.__getitem__(0)\n",
        "t[0].shape, t[1].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((2, 1024, 1024, 3), (2, 1048576, 51))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGIMROr2DIC2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMTydN2UCNDj",
        "colab_type": "code",
        "outputId": "efede74f-c628-48f9-bec3-426ab9d74c85",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        }
      },
      "source": [
        "# test 1\n",
        "img_input = Input(shape=(input_height,input_width , 3 ))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
        "conv1 = Dropout(0.2)(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D((2, 2))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Dropout(0.2)(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Dropout(0.2)(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "up1 = concatenate([UpSampling2D((2, 2))(conv3), conv2], axis=-1)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv4 = Dropout(0.2)(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "\n",
        "up2 = concatenate([UpSampling2D((2, 2))(conv4), conv1], axis=-1)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv5 = Dropout(0.2)(conv5)\n",
        "conv5 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv5)\n",
        "# conv5 = Conv2D(32, (3, 3), activation='softmax', padding='same')(conv5)\n",
        "\n",
        "out = Conv2D(n_classes, (1, 1) , padding='same')(conv5)\n",
        "out = Reshape((input_height*input_width, -1))(out)\n",
        "out = Activation('softmax')(out)\n",
        "\n",
        "'''\n",
        "# test 2\n",
        "img_input = Input(shape=(input_height,input_width , 3 ))\n",
        "\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\n",
        "conv1 = Dropout(0.2)(conv1)\n",
        "conv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\n",
        "pool1 = MaxPooling2D((4, 4))(conv1)\n",
        "\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\n",
        "conv2 = Dropout(0.2)(conv2)\n",
        "conv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\n",
        "pool2 = MaxPooling2D((2, 2))(conv2)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\n",
        "conv3 = Dropout(0.3)(conv3)\n",
        "conv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\n",
        "\n",
        "u3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (conv3)\n",
        "up1 = concatenate([u3, conv2], axis=-1)\n",
        "\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\n",
        "conv4 = Dropout(0.3)(conv4)\n",
        "conv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "# pool3 = MaxPooling2D((2, 2))(conv4)\n",
        "conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\n",
        "conv5 = Dropout(0.2)(conv5)\n",
        "conv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\n",
        "\n",
        "u4 = Conv2DTranspose(32, (2, 2), strides=(4, 4), padding='same') (conv5)\n",
        "up2 = concatenate([u4, conv1], axis=-1)\n",
        "\n",
        "conv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\n",
        "conv6 = Dropout(0.1)(conv6)\n",
        "conv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv6)\n",
        "\n",
        "out = Conv2D(n_classes, (1, 1) , padding='same')(conv6)\n",
        "\n",
        "out = Reshape((input_height*input_width, -1))(out)\n",
        "out = Activation('softmax')(out)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2239: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# test1\\nimg_input = Input(shape=(input_height,input_width , 3 ))\\n\\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(img_input)\\nconv1 = Dropout(0.2)(conv1)\\nconv1 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv1)\\npool1 = MaxPooling2D((4, 4))(conv1)\\n\\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(pool1)\\nconv2 = Dropout(0.2)(conv2)\\nconv2 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv2)\\npool2 = MaxPooling2D((2, 2))(conv2)\\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(pool2)\\nconv3 = Dropout(0.3)(conv3)\\nconv3 = Conv2D(128, (3, 3), activation='relu', padding='same')(conv3)\\n\\nu3 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (conv3)\\nup1 = concatenate([u3, conv2], axis=-1)\\n\\nconv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(up1)\\nconv4 = Dropout(0.3)(conv4)\\nconv4 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\\n# pool3 = MaxPooling2D((2, 2))(conv4)\\nconv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv4)\\nconv5 = Dropout(0.2)(conv5)\\nconv5 = Conv2D(64, (3, 3), activation='relu', padding='same')(conv5)\\n\\nu4 = Conv2DTranspose(32, (2, 2), strides=(4, 4), padding='same') (conv5)\\nup2 = concatenate([u4, conv1], axis=-1)\\n\\nconv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(up2)\\nconv6 = Dropout(0.1)(conv6)\\nconv6 = Conv2D(32, (3, 3), activation='relu', padding='same')(conv6)\\n\\nout = Conv2D(n_classes, (1, 1) , padding='same')(conv6)\\n\\nout = Reshape((input_height*input_width, -1))(out)\\nout = Activation('softmax')(out)\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnVR2gGXDExG",
        "colab_type": "code",
        "outputId": "9e419f8e-bd23-48c0-e4d0-d6e5f5111eae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = Model(img_input, out)\n",
        "# model.compile(optimizer='adadelta', loss=loss,  metrics=['accuracy'])\n",
        "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 1024, 1024, 3 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 1024, 1024, 3 896         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, 1024, 1024, 3 0           conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 1024, 1024, 3 9248        dropout_1[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 512, 512, 32) 0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 512, 512, 64) 18496       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512, 512, 64) 0           conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 512, 512, 64) 36928       dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 256, 256, 64) 0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 256, 256, 128 0           conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 256, 256, 128 147584      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2D)  (None, 512, 512, 128 0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 512, 512, 192 0           up_sampling2d_1[0][0]            \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 512, 512, 64) 110656      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_4 (Dropout)             (None, 512, 512, 64) 0           conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 512, 512, 64) 36928       dropout_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2D)  (None, 1024, 1024, 6 0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 1024, 1024, 9 0           up_sampling2d_2[0][0]            \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 1024, 1024, 3 27680       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_5 (Dropout)             (None, 1024, 1024, 3 0           conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 1024, 1024, 3 9248        dropout_5[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 1024, 1024, 5 1683        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "reshape_1 (Reshape)             (None, 1048576, 51)  0           conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 1048576, 51)  0           reshape_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 473,203\n",
            "Trainable params: 473,203\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAgVIoQEbE4b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fit generator\n",
        "filepath = root_path + \"outputs/weights_best_dominik_cell_1_adam.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=True, mode='max', period=1)\n",
        "# reduces learning rate on plateau\n",
        "lr_reducer = ReduceLROnPlateau(factor=0.1,\n",
        "                               cooldown= 10,\n",
        "                               patience=10, verbose=1,\n",
        "                               min_lr=0.1e-5)\n",
        "# stop learining as metric on validatopn stop increasing\n",
        "early_stopping = EarlyStopping(patience=10, verbose=1, mode = 'auto')\n",
        "callbacks_list = [checkpoint, early_stopping, lr_reducer]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXSBB7W1P8iS",
        "colab_type": "code",
        "outputId": "4311a5e2-e887-4be8-faac-04bb98e4bf8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit_generator(train_generator, validation_data=val_generator, epochs=10, steps_per_epoch=256, callbacks=callbacks_list, workers=2, use_multiprocessing=True, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "256/256 [==============================] - 7381s 29s/step - loss: 2.0338 - acc: 0.6475 - val_loss: 1.3076 - val_acc: 0.6667\n",
            "\n",
            "Epoch 00001: acc improved from -inf to 0.64754, saving model to gdrive/My Drive/tabOCR/outputs/weights_best_test3_cell_adam.hdf5\n",
            "Epoch 2/10\n",
            "201/256 [======================>.......] - ETA: 30:27 - loss: 1.1938 - acc: 0.6811"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Process ForkPoolWorker-45:\n",
            "Process ForkPoolWorker-1:\n",
            "Process ForkPoolWorker-2:\n",
            "Process ForkPoolWorker-46:\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 258, in _bootstrap\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
            "    put((job, i, result))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
            "    with self._wlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 125, in worker\n",
            "    put((job, i, result))\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 346, in put\n",
            "    with self._wlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 93, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "KeyboardInterrupt\n",
            "  File \"/usr/lib/python3.6/multiprocessing/pool.py\", line 108, in worker\n",
            "    task = get()\n",
            "  File \"/usr/lib/python3.6/multiprocessing/queues.py\", line 334, in get\n",
            "    with self._rlock:\n",
            "  File \"/usr/lib/python3.6/multiprocessing/synchronize.py\", line 95, in __enter__\n",
            "    return self._semlock.__enter__()\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5746b10b718b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1656\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1657\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1658\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mbatch_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0msteps_done\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mgenerator_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__len__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/utils/data_utils.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    601\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m                     \u001b[0mfuture\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m                     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    604\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask_done\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 638\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    639\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    633\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 635\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    637\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    549\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rNDQMSqcoZ2",
        "colab_type": "code",
        "outputId": "522f08d4-5590-4cf0-ca3c-d09191178170",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        }
      },
      "source": [
        "def predict(model, file_name_img, file_name_mask, input_height, input_width,\n",
        "            n_classes):\n",
        "    img_test = cv2.imread(file_name_img, 1)\n",
        "    img_mask = cv2.imread(file_name_mask, 0)\n",
        "    img_mask = cv2.resize(img_mask, (input_height, input_width),\n",
        "                          interpolation=cv2.INTER_NEAREST)\n",
        "    img_test = cv2.resize(img_test, (input_height, input_width),\n",
        "                          interpolation=cv2.INTER_NEAREST)\n",
        "    img_test = np.expand_dims(img_test, axis=0)\n",
        "    mask_pred = model.predict(img_test)\n",
        "    mask_pred = mask_pred.reshape((input_height, input_width, n_classes)).\\\n",
        "        argmax(axis=2)\n",
        "    plt.figure(figsize=(32, 32))\n",
        "    plt.subplot(1, 3, 1)\n",
        "    plt.imshow(img_test[0])\n",
        "    plt.subplot(1, 3, 2)\n",
        "    plt.imshow(img_mask)\n",
        "    plt.subplot(1, 3, 3)\n",
        "    plt.imshow(mask_pred)\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "predict(model, \"img_table_val/54_table.png\", \"img_mask_cell_val/54_table.png\", input_height, input_width, n_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABygAAAIwCAYAAADd3zwxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKAEAAAAAAIBhFJQAAAAAAADAMP8H5aWZKpYCUBIAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 2304x2304 with 3 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttOxoytcDnc0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}